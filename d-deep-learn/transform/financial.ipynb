{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a325ba0",
   "metadata": {},
   "source": [
    "### Transformer for prediction \n",
    " The goal is to predict whether the next X(x=6)-minute close of BAP will be higher than the current close, and to feel first-hand how self-attention:\n",
    "\n",
    "**Puntos clave en Transformers:**\n",
    "\n",
    "- **B, L, D**\n",
    "- Los más importantes:\n",
    "  - **L** es la longitud de secuencia\n",
    "  - **D** es el tamaño del embedding o los features que tenga el caso de uso\n",
    "\n",
    "---\n",
    "\n",
    "- **L** para este ejemplo es el tamaño de la secuencia de intervalos diarios,  \n",
    "  en el ejemplo se toman diferentes secuencias de forma aleatoria.\n",
    "- **D** es el número de features: price closed, volumen, etc.\n",
    "\n",
    "---\n",
    "\n",
    "**En el dataset tiene la forma `29x49x5`:**\n",
    "\n",
    "- 29 es el número de días útiles de trading\n",
    "- 49 es la cantidad de intervalos diarios (bars),  \n",
    "  o sea, número máximo de intervalos en un día.  \n",
    "  Para el entrenamiento se toma por ejemplo una secuencia fija de 32  \n",
    "  pero se van extrayendo de forma aleatoria de los 49\n",
    "  (considere que para este caso cada bar equivale a 2min)\n",
    "- 5 cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5575a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf, pandas as pd, torch, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "048378de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(d, d, bias=False)\n",
    "        self.k = nn.Linear(d, d, bias=False)\n",
    "        self.v = nn.Linear(d, d, bias=False)\n",
    "        self.scale = math.sqrt(d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.q(x)\n",
    "        K = self.q(x)\n",
    "        V = self.q(x)\n",
    "        score = Q @ K.transpose(-2, -1) / self.scale  # BxLxL\n",
    "        attn_w = F.softmax(score, dim=-1)\n",
    "        context = attn_w @ V\n",
    "        return context, attn_w\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int, f: int):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(d, f)\n",
    "        self.l2 = nn.Linear(f, d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(F.gelu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d80e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int, d_f: int):\n",
    "        super().__init__()\n",
    "        self.attn = SelfAttention(d)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff = FeedForward(d, d_f)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "        context, atten = self.attn(x)\n",
    "        x = self.norm1(x + context)\n",
    "        x = self.norm2(x + self.ff(x))\n",
    "        \n",
    "        return (x, atten if return_attention else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f866db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinanceTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim=5, d=32, d_f=64):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(in_dim, d)\n",
    "        self.enc = EncoderLayer(d, d_f)\n",
    "        self.cls = nn.Linear(d, 1)\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "        x = self.proj(x)\n",
    "        x, attn = self.enc(x, return_attention=True)\n",
    "        logits = self.cls(x).squeeze(-1)\n",
    "\n",
    "        return (logits, attn) if return_attention else logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cacbc464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22424/1497174375.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(TICKER, period=PERIOD, interval=INTERVAL, progress=False)\n"
     ]
    }
   ],
   "source": [
    "TICKER   = \"BAP\"\n",
    "PERIOD   = \"60d\"\n",
    "INTERVAL = \"2m\"\n",
    "df = yf.download(TICKER, period=PERIOD, interval=INTERVAL, progress=False)\n",
    "df = df.between_time(\"09:30\", \"16:00\")  # Regular trading hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "298e8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = (df[\"Close\"].shift(-3) > df[\"Close\"]).astype(int)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "66ea9048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>BAP</th>\n",
       "      <th>BAP</th>\n",
       "      <th>BAP</th>\n",
       "      <th>BAP</th>\n",
       "      <th>BAP</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-06-06 13:30:00+00:00</th>\n",
       "      <td>217.270004</td>\n",
       "      <td>217.270004</td>\n",
       "      <td>217.270004</td>\n",
       "      <td>217.270004</td>\n",
       "      <td>3010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-06 13:36:00+00:00</th>\n",
       "      <td>217.979996</td>\n",
       "      <td>217.979996</td>\n",
       "      <td>217.979996</td>\n",
       "      <td>217.979996</td>\n",
       "      <td>2035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-06 13:38:00+00:00</th>\n",
       "      <td>217.889999</td>\n",
       "      <td>217.889999</td>\n",
       "      <td>217.889999</td>\n",
       "      <td>217.889999</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-06 13:40:00+00:00</th>\n",
       "      <td>218.210007</td>\n",
       "      <td>218.210007</td>\n",
       "      <td>218.210007</td>\n",
       "      <td>218.210007</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-06 13:46:00+00:00</th>\n",
       "      <td>216.089996</td>\n",
       "      <td>217.154999</td>\n",
       "      <td>216.089996</td>\n",
       "      <td>217.154999</td>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 15:46:00+00:00</th>\n",
       "      <td>228.860001</td>\n",
       "      <td>228.880005</td>\n",
       "      <td>228.479996</td>\n",
       "      <td>228.500000</td>\n",
       "      <td>25563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 15:48:00+00:00</th>\n",
       "      <td>228.490005</td>\n",
       "      <td>228.860001</td>\n",
       "      <td>228.490005</td>\n",
       "      <td>228.860001</td>\n",
       "      <td>14219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 15:50:00+00:00</th>\n",
       "      <td>228.690002</td>\n",
       "      <td>228.690002</td>\n",
       "      <td>228.675003</td>\n",
       "      <td>228.675003</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 15:54:00+00:00</th>\n",
       "      <td>228.889999</td>\n",
       "      <td>228.889999</td>\n",
       "      <td>228.750000</td>\n",
       "      <td>228.750000</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 15:58:00+00:00</th>\n",
       "      <td>228.940002</td>\n",
       "      <td>228.940002</td>\n",
       "      <td>228.940002</td>\n",
       "      <td>228.940002</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                           Close        High         Low        Open  \\\n",
       "Ticker                            BAP         BAP         BAP         BAP   \n",
       "Datetime                                                                    \n",
       "2025-06-06 13:30:00+00:00  217.270004  217.270004  217.270004  217.270004   \n",
       "2025-06-06 13:36:00+00:00  217.979996  217.979996  217.979996  217.979996   \n",
       "2025-06-06 13:38:00+00:00  217.889999  217.889999  217.889999  217.889999   \n",
       "2025-06-06 13:40:00+00:00  218.210007  218.210007  218.210007  218.210007   \n",
       "2025-06-06 13:46:00+00:00  216.089996  217.154999  216.089996  217.154999   \n",
       "...                               ...         ...         ...         ...   \n",
       "2025-07-22 15:46:00+00:00  228.860001  228.880005  228.479996  228.500000   \n",
       "2025-07-22 15:48:00+00:00  228.490005  228.860001  228.490005  228.860001   \n",
       "2025-07-22 15:50:00+00:00  228.690002  228.690002  228.675003  228.675003   \n",
       "2025-07-22 15:54:00+00:00  228.889999  228.889999  228.750000  228.750000   \n",
       "2025-07-22 15:58:00+00:00  228.940002  228.940002  228.940002  228.940002   \n",
       "\n",
       "Price                     Volume label  \n",
       "Ticker                       BAP        \n",
       "Datetime                                \n",
       "2025-06-06 13:30:00+00:00   3010     1  \n",
       "2025-06-06 13:36:00+00:00   2035     0  \n",
       "2025-06-06 13:38:00+00:00    135     0  \n",
       "2025-06-06 13:40:00+00:00    662     0  \n",
       "2025-06-06 13:46:00+00:00    863     1  \n",
       "...                          ...   ...  \n",
       "2025-07-22 15:46:00+00:00  25563     1  \n",
       "2025-07-22 15:48:00+00:00  14219     1  \n",
       "2025-07-22 15:50:00+00:00    569     0  \n",
       "2025-07-22 15:54:00+00:00   1692     0  \n",
       "2025-07-22 15:58:00+00:00   1002     0  \n",
       "\n",
       "[1528 rows x 6 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fecf76b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero real de dias de trading\n",
    "steps_per_day = int(len(df) / len(df.index.normalize().unique()))\n",
    "n_days = len(df) // steps_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea4b092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: OHLCV\n",
    "cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "X1 = df[cols].values[:n_days * steps_per_day].reshape(n_days, steps_per_day, len(cols))\n",
    "y = df[\"label\"].values[:n_days * steps_per_day].reshape(n_days, steps_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4be90929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X1.reshape(-1, len(cols))).reshape(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39be88aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.78244663,  1.90998904,  1.81771779,  1.78653107, 13.55621035])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac3f5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = FinanceTransformer().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e24a63e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.7144\n"
     ]
    }
   ],
   "source": [
    "# usamos un tamaño de sequencia de 32\n",
    "# sin embargo el tamaño maximo puede ser el numero de pasos por dia \n",
    "seq_len = 32  \n",
    "\n",
    "for epoch in range(1):\n",
    "    epoch_loss = 0\n",
    "    for i in range(n_days):\n",
    "        # Pick random window of length seq_len\n",
    "        k = np.random.randint(0, steps_per_day - seq_len - 3)\n",
    "        xb = torch.tensor(X[i:i+1, k:k+seq_len, :], dtype=torch.float32).to(device)\n",
    "        yb = torch.tensor(y[i:i+1, k:k+seq_len], dtype=torch.float32).to(device)\n",
    "        logits, _ = model(xb, return_attention=True)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} loss: {epoch_loss / n_days:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70ebd44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49, 5])\n",
      "prediction is  tensor([[-0.3402, -0.3046, -0.3002, -0.3091, -0.3337, -0.3375, -0.2988, -0.2964,\n",
      "         -0.3076, -0.3053, -0.3065, -0.3114, -0.3055, -0.3346, -0.3077, -0.2988,\n",
      "         -0.2915, -0.2920, -0.2915, -0.2977, -0.2612, -0.3110, -0.3100, -0.3730,\n",
      "         -0.3062, -0.3314, -0.3578, -0.3215, -0.3346, -0.3199, -0.3184, -0.3212,\n",
      "         -0.3448, -0.3634, -0.3574, -0.3378, -0.3349, -0.3366, -0.3314, -0.3324,\n",
      "         -0.3452, -0.3396, -0.3332, -0.3700, -0.3300, -0.3296, -0.3568, -0.3486,\n",
      "         -0.3331]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x1 = X[-2:-1, :, :]\n",
    "x1 = torch.tensor(x1, dtype=torch.float32)\n",
    "print(x1.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(x1)\n",
    "    print('prediction is ', pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsroad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
